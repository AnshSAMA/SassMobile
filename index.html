<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="css/main.css">
    <link href="https://fonts.googleapis.com/css2?family=Signika&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300&display=swap" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css2?family=Karla&display=swap" rel="stylesheet">
    <title>SassMobile</title>
  </head>
  <body>

    <!-- Navbar -->
    <nav class="navbar navbar-expand-md navbar-dark navbar-custom-color fixed-top">
      <div class="container-fluid">
        <!-- Brand Declaration -->
        <a href="index.html" class="navbar-brand">SassMobile</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <!-- Navbar Items -->
            <!-- Add Active classes here -->
            <li class="nav-item">
              <a class="nav-link" href="#product-intro">Product</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#design-process">Design</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#reflection">Reflection</a>
            </li>
			<li class="nav-item">
              <a class="nav-link" href="https://ixd-2020.uqcloud.net" >Back to IXD-2020 site</a>
            </li>
      </div>
    </nav>

<!-- Image Slider/ Carousel -->
    <div id="carouselExampleIndicators" class="carousel slide carousel-section" data-ride="carousel">
      <ol class="carousel-indicators">
        <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
        <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
        <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
      </ol>
      <div class="carousel-inner">
        <div class="carousel-item active carousel-images">
          <img src="img/CarouselFinalProduct.jpg" class="d-block w-100" alt="...">
          <div class="carousel-caption carousel-text-modi align-middle">
            <h2 class="display-3 heading-text-carousel">SassMobile</h2>
            <h4 class="sub-text-carousel">Reducing screen time through sass,</h4>
            <h4 class="sub-text-carousel">annoying people out of couch</h4>
            <!-- <button class="btn btn-primary btn-lg">Learn More</button> -->
          </div>
        </div>
        <div class="carousel-item carousel-images">
          <img src="img/CarouselSlideThree.jpg" class="d-block w-100" alt="...">
          <div class="carousel-caption carousel-slide2">
            <h2 class="display-3 heading-text-carousel">Interactive</h2>
            <h4 class="sub-text-carousel">Changes personality based on actions</h4>
          </div>
        </div>
        <div class="carousel-item carousel-images">
          <img src="img/CarouselSlideTwo.jpg" class="d-block w-100" alt="...">
          <div class="carousel-caption carousel-slide2">
            <h2 class="display-3 heading-text-carousel">Playful</h2>
            <h4 class="sub-text-carousel">Reacts to interactions</h4>
          </div>
        </div>
      </div>
      <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
        <span class="carousel-control-next-icon" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
      </a>
    </div>

    <!-- Problem Space and Solution -->
    <div id="problem-and-sol" class="container-fluid padding ps-and-sol">
      <div class="row padding justify-content-center">
        <div class="col-md-5">
          <div class="card text-white p-custom-color">
            <div class="card-body">
              <h4 class="card-title">Problem Space</h4>
              <p class="card-text">
                We started with <b>Sassy Tech</b> as our team domain, where we explored technologies with sass. To give the tech a purpose, we decided to tackle the issue regarding the overuse of technology. Observing the current times where people are stuck to screens, we further narrowed down our problem space to focus on stopping people from watching screens, i.e. <b>reduce screen time</b>. Hence, we worked on using sassy tech to reduce screen time of people.
              </p>
            </div>
          </div>
        </div>

        <div class="col-md-5">
          <div class="card text-white s-custom-color">
            <div class="card-body">
              <h4 class="card-title">The Solution</h4>
              <p class="card-text">
                To stop users from focussing on screens for long periods, we created a sassy robot which annoys users through variety of mediums and disturbs their TV watching experience. The robot can talk, play with you and if angered, gain control over your devices. User can interact with robot to try to stop it from annoying them. While this gives them temporary relief from the annoyance but, the interactions have long-term impact on the behaviour of the robot.
              </p>
            </div>
          </div>
        </div>

      </div>
    </div>

    <!-- Product Intro -->
    <div id="product-intro" class = "container-fluid padding">
      <h2 class="title-h2">So, how does it work?</h2>
      <hr class="h2-underline text-left"></hr>
      <div class="row padding justify-content-around align-items-center">
        <div class="col-md-5 padding">
          <p class="product-intro-para">
            SassMobile, with Roomba as it's chariot zooms around the house trying to find people on screens. When a user is detected, the robot warns them about overusing. If the screen is turned off, the robot stops annoying and starts moving around the house again. But, if the advice is ignored, the robot takes the sassy approach. Henceforth, the robot starts sassing user until they gets off the TV. The robot can be stopped through interactions but beware, it's sassiness might increase as user tries to stop it. Therefore, the robot reacts based on on how user behaves with it, i.e. <em>"worse the robot is treated, sassier it becomes".</em></p>
            <p class="product-intro-para">
              Through the interactions with robot, guilt is induced in users to stop watching them from watching screen. Alternatively, even if the user doesn't feel guilty, eventually due to robot's control over user's devices, they are forced to get off their screens. In the end, either user gives up or they are forced to give up ultimately reducing their screen time.
            </p>
        </div>
        <div class="col-md-5">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/qgTYB5lY7wg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <hr class="design-hr">

    <!-- What can our robot do? -->
    <div class="container-fluid padding" style="padding-top: 1%;">
      <h2>What can our robot do?</h2>
      <hr class="h2-underline text-left"></hr>
      <div class="row padding">
        <div class="col-xs-12 col-sm-6 col-md-4">
          <div class="card">
            <img src="img/talk.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Talk</h4>
              <p class="card-text">
                SassMobile can talk to user, advice them and give sassy comments. <a href="https://ixd-2020.uqcloud.net/williams/">(see Ben William's portfolio)</a>
              </p>
            </div>
          </div>
        </div>
        <div class="col-xs-12 col-sm-6 col-md-4">
          <div class="card">
            <img src="img/interact.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Interact</h4>
              <p class="card-text">
                Our robot has multiple interactions and reactions to user interaction. <a href="#input-interac">(my individual focus)</a>
              </p>
            </div>
          </div>
        </div>
        <div class="col-xs-12 col-sm-6 col-md-4">
          <div class="card">
            <img src="img/control_devices.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Control Devices</h4>
              <p class="card-text">
                The robot can reduce TV volume, change channels and turn off the TV. <a href="https://ixd-2020.uqcloud.net/harper/">(see Tim Harper's portfolio)</a>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>

    <hr>

    <!-- Input Interactions -->
    <div class="container-fluid padding" id="input-interac">
      <h2 class="title-h2">Input Interactions</h2>
      <hr class="h2-underline text-left"></hr>
      <p class="para-paddings-intro">
        A crucial part of shaping robot’s personality are the input interactions, i.e ways a user interacts with the robot. A user may interact with robot to stop it from annoying them temporarily. Input interaction's are designed to provoke self-reflection in users and guilt them. This is my focus in the project, the input interactions that takes user’s anger (negative interactions) and shapes the personality of robot. As mentioned before, this follows the theme of <em>you get as you do</em>. As an alternative, users can also use positive interactions to make robot happy and stop the robot without changing robot's personality but the positive interactions are more time consuming & requires more effort from the user. Therefore, it is user's choice to use positive interactions and make robot happy or use negative ones and anger the robot. There are four different interactions present within robot that stops four different functionalities of robot. The effects of interacting with robot can also be seen on robot's face as it's smile turns to frown using different led effects. Different led effects and reactions (smile turning to frown) are used to provide emotional feedback to user and induce guilt in them. The four interactions present in robot are:
      </p>
      <hr class="design-hr">
      <div class="row padding">
        <!-- Volume Control -->
        <div class="col-md-6">
          <h4 class="text-center"><u class="sub-green-underline">Volume Control</u></h4>
          <p class="para-paddings">
            If the user feels that robot is being loud, they can use volume control located on the mouth of robot and adjust the volume. Turn the volume control towards right to lower volume and towards left to increase it. As the volume is lowered, it's effects are also visible on robot as the smile slowly turns to frown with the led effects similar to how volume is lowered on TV, i.e. volume bar reducing. This interaction is useful when robot speaks a lot and user wants relief from all the nagging and constant sassing of robot.<br>No volume = No speaking
          </p>
          <img src="img/volume_changed.gif" class="rounded mx-auto d-block">
        </div>
        <div class="col-md-6">
          <!-- Eye Sight -->
          <h4 class="text-center"><u class="sub-green-underline">Blinding Robot</u></h4>
          <p class="para-paddings">
            If the user is working or just doesn't want to be disturbed, they can stop robot's movement by blinding it. Simply cover the eye of robot and robot is unable to see and move around. This interaction is particularly useful to stop robot at particular part of house, i.e. stop it before it finds the user. For led effects, the robot's smile disappears as it sees less, indicating that happiness of robot fades as light fades in robot's eye. User also has option to make robot happy by placing the robot in place with lots of light (positive interaction). The robot smiles similar to massaging ears.
          </p>
          <img src="img/blind_eye.gif" class="rounded mx-auto d-block">
        </div>
      </div>

      <div class="row padding">
        <!-- Scolding -->
        <div class="col-md-6">
          <h4 class="text-center"><u class="sub-green-underline">Scolding</u></h4>
          <p class="para-paddings">
            Pulling ears interaction is part of aggressive interactions used to scold the robot. If the robot becomes naughty, user can scold it to stop robot temporarily. Just grab the ear of the robot and start pulling it. The stronger the ear is pulled, the angrier the robot is. This discomfort of robot is also expressed through it's frown where, the brightness of robot is indicator of how hard ear is being pulled. Alternatively, user can massage the ear of robot (slight touch) to make it happy. Massaging robot takes more effort as it's a constant action. Smile going up indicates positive interaction.
          </p>
          <img src="img/ear_pull.gif" class="rounded mx-auto d-block">
        </div>

        <div class="col-md-6">
        <!-- Startling -->
          <h4 class="text-center"><u class="sub-green-underline">Throwing Stuff</u></h4>
          <p class="para-paddings">
            If the user is annoyed, they can express their anger by throwing stuff at robot. Just grab any object and throw it towards robot to take out your anger on the robot. Additionally, other gestures like shaking and slapping the robot also deliver the same effects, i.e. stop robot temporarily. Led effects here are simple but the frown stays for longer period than other interactions, indicating the lasting impact of aggression on it's psychology. This triggers self-reflection on user about their behaviour towards the robot.
          </p>
          <img src="img/throwing_stuff_two.gif" class="rounded mx-auto d-block">
        </div>
      </div>
    </div>

    <!-- How they work -->
    <hr class="design-hr" style="padding-bottom: 2%;">
    <div class="container-fluid padding">
      <hr>
      <h2>How it's made?</h2>
      <hr class="h2-underline text-left"></hr>
      <h3 class="text-center"><u class="sub-green-underline" >Sensors Used</u></h3>
      <div class="row padding" style="margin-top:2%;">
        <div class="col-xs-12 col-sm-6 col-md-3">
          <div class="card">
            <img src="img/Potentiometer.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Potentiometer</h4>
              <p class="card-text">
                Used in the volume control interaction. Potentiometer's input is used as the number of led's displayed to get the bar volume effect
              </p>
            </div>
          </div>
        </div>
        <div class="col-xs-12 col-sm-6 col-md-3">
          <div class="card">
            <img src="img/photocell.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Photocell</h4>
              <p class="card-text">
                Acting as eye of robot, photocell senses light. The amount of light on photocell tells how much bright the leds should be.
              </p>
            </div>
          </div>
        </div>
        <div class="col-xs-12 col-sm-6 col-md-3">
          <div class="card">
            <img src="img/pressure_sensor.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Force Sensitive Resistor</h4>
              <p class="card-text">
                Located underneath the ears, the FSR inputs the pressure applied on it. This sensor is used for scolding interaction.
              </p>
            </div>
          </div>
        </div>
        <div class="col-xs-12 col-sm-6 col-md-3">
          <div class="card">
            <img src="img/piezo_sensor.jpg" class="card-img-top">
            <div class="card-body">
              <h4 class="card-title">Piezo Element</h4>
              <p class="card-text">
                Piezo element is used for detecting vibration. Hence, it can detect when user throws stuff or slaps/shakes the robot.
              </p>
            </div>
          </div>
        </div>
      </div>
      <h3 class="text-center"><u class="sub-green-underline">Working Behind</u></h3>
      <div class="row padding justify-content-between" style="margin-top:2%;">
        <div class="row padding justify-content-around align-items-center">
          <div class="col-md-5 padding">
            <p class="product-intro-para">
              Various sensors are combined together in the breadboard. All the aforementioned sensors are set up in various part of robot's face. Potentiometer in lips, photocell in eyes, FSR underneath ears and piezo element inside robot's body. Connected through jumper cables, the sensors read the values constantly and using arduino IDE, the values are converted to desired led effects. The code also keeps track of how many times sensors are used and uses this variable for making robot speak. For example, if sensors are used less than three times, the robot warns with sentence like "I think you have watched enough" but, if used more than 3 times, the robot starts being sassy with sentence such as "It's a beautiful day outside, not that you would know".
            </p>
              <p class="product-intro-para">
                The code used can be viewed
                <a href="https://drive.google.com/file/d/1didYuL5OB4KsoAlve-agaZEth-1jDa7K/view?usp=sharing">here</a> & arduino file downloaded from <a href="https://drive.google.com/file/d/1bjx23tzskRvKuEc7732Ts9LgsVQMtkWt/view?usp=sharing">here</a>. Code here is combination of my and Ben's functionality combined.
              </p>
          </div>
          <div class="col-md-5">
            <img src="img/circuit_two.jpg" class="circuit-image">
            <p class="text-center">*Circuit for the final build*</p>
          </div>
        </div>
      </div>
    </div>

    <hr>
    <!-- Design Process -->
    <div id="design-process" class="container-fluid padding">
      <h2>Design Process</h2>
      <hr class="h2-underline text-left"></hr>
      <div class="para-paddings">
        <h3 class="text-center"><u class="sub-green-underline">The Start:</u></h3>
        <p>
          Starting out, our goal was to use interactions that allowed users to stop robot from sassing while also inducing guilt in user. So, while brainstorming we used robot’s body and disabling parts of it as our input interactions. Each interaction stopped a particular functionality of robot and hence stopped the sassing of robot. Being cruel interactions, we hoped to guilt the users and make them self-reflect.
        </p>
        <img src="img/start.jpg" class="design-images rounded mx-auto d-block">
        <p class="text-center"> *Initial Interactions* </p>
        <p>
            While the above interactions fulfilled our purposes, it was quickly realised through feedback from teachers and colleagues that the interactions can be easily mistaken as torture, which we didn’t want considering teens as potential users. Therefore, we moved forward dropping these interactions and moving onto research for inspiration. The idea of manipulating body parts was still intact.
        </p>
      </div>

      <hr class="design-hr">
      <div class="para-paddings">
        <h3 class="text-center"><u class="sub-green-underline">Research:</u></h3>
        <p>
          While researching, my goal was to look into existing robots with personality and observe how they engage with the users. Observing social robot Sophia and assistant robot Olly, it was noted that these robot takes user’s emotions as their inputs and use it change themselves. This what intrigued people, their ability to change according to user. This was useful as I got the idea of using user's anger as the input interactions. It would great for robot to change itself based on how user treats it and progress it's behaviour/personality based on it. Combining the manipulation of body to stop particular functionality of robot and inputting anger as interaction, I came up with four new interactions that resembled previous interactions but had meaning for each interaction. Two of interactions were used to input passive anger for people who are passive and the other two interactions were more confronting/aggressive. Volume Control and Block View interactions are passive whereas Ear Pull and Shaking interactions are aggressive.
        </p>
        <img src="img/research.jpg" class="design-images-two rounded mx-auto d-block">
        <p class="text-center"> *New Interactions* </p>
        <p>
          I had laid down a base for the input interactions but wasn't sure if this made sense to the user's and whether the interactions were successful in guilting them so, testing was conducted to explore this.
        </p>
      </div>

      <hr class="design-hr">
      <div class="para-paddings">
        <h3 class="text-center"><u class="sub-green-underline">Testing:</u></h3>
        <p>
          In the penultimate stage of design, a test was conducted to further grasp the concept from user’s viewpoint and verify if they understood the concept. The test was conducted in a form of survey where questions revolved around exploring the concept. Survey results can be viewed <a href="https://forms.gle/PdJi6V4Ubho8wxc4A">here</a>. The main takeaways from survey were –
          <ul>
            <li>
              Alongside interactions that takes in user’s anger, there should also be positive interactions that balance out the negative. These interactions also gives users chance to redeem and correct their mistakes
              <img src="img/survey_test_one.PNG" class="survey-results rounded mx-auto d-block">
              <img src="img/survey_test_two.PNG" class="survey-results rounded mx-auto d-block">
              It is explicit from answers above that testers were trying to include positive interactions.
            </li>
            <li>
              Reactions should be added where robot retaliates to the use of interactions. The reactions would be helpful to indicate to user's that using interactions makes robot unhappy/angry.
              <img src="img/survey_test_three.PNG" class="survey-results rounded mx-auto d-block">
              Tester's reply indicates that robot should express it's discomfort.
            </li>
          </ul>
          <p>
            Following the results, two features were added to the robot -
          </p>
          <ul>
            <li>
              A positive interaction where user can tap on robot's head to make it happy. This interaction stops the robot and make it happy but requires more effort since user has to continuously do it. Here, we give user chance to choose between their comfort or robot's mood.
            </li>
            <li>
              Smile and frown given to robot as reactions. The mouth region now shows the mood of the robot when an interaction is used.
            </li>
          </ul>
        </p>
        <p>
          After testing, we were looking forward to protoype demonstration where we shared our prototype with class mates.
        </p>
      </div>
      <hr class="design-hr">
      <div class="para-paddings">
        <h3 class="text-center"><u class="sub-green-underline">Prototye Demonstration:</u></h3>
        <p>
          The final stage of concept development consisted of building a physical prototype to get feedback from fellow students. All the features aforementioned were implemented in the prototype and displayed to students in the an explainer video. Video was used to show prototype because of COVID-19 restrictions. A complementing document was also provided to students in order to further their understanding of concept. The document can be read <a href="https://drive.google.com/file/d/1eXKc8ua_iD-J6CMy-_GzXKLAzIQ_ndXI/view?usp=sharing">here</a>. The document contains problem space, design process, interaction plan and success criteria.
            <div class="row padding align-items-center justify-content-between">
              <div class="col-md-6 justify-content-center">
                <img src="img/prototype_three.jpg" class="design-images-three">
                <p>*Prototype developed and sensors used*</p>
              </div>
              <div class="col-md-6">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/qgTYB5lY7wg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                <p>*Explainer Video*</p>
              </div>
            </div>
            <p>
              After the video was reviwed by class mates, we were given appraisals about our concept. Main takeways from appraisals were -
            </p>
            <li>
              The positive interactions present made sense but there should be more. The positive interactions helps better user's control over robot's personality.
              <img src="img/feedback_two.PNG" class="survey-results rounded mx-auto d-block">
            </li>
            <li>
              Smile and frown works well to provide anthropomorphic feedback and give users emotional connection to robot. Similar features can be added that help with guilting the users.
              <img src="img/feedback_one.PNG" class="survey-results rounded mx-auto d-block">
            </li>
          </ul>
          <br>
          <p>
            Considering the appraisals, two changes were made to concept and protoype.
          </p>
          <ul>
            <li>
              Two interactions were modified, blinding robot and scolding. If robot is kept in sunlight, this would be a positive interaction where robot will get good light, opposite to when robot is blinded. Users can also massage the ears of robot to make it happy. The modification of two existing interactions would act as the positive interactions.
            </li>
            <li>
              Led effects were added to smile and frown. The effects shows emotional changes to the state of robot. For example, as volume is lowered the smile of robot turns to frown one led at a time, similar to how volume bar is reduced. Led effects are also explained in Input Interactions section.
            </li>
          </ul>
        </p>
      </div>

      <div class="para-paddings">
        <h3 class="text-center"><u class="sub-green-underline">Final Build:</u></h3>
        <p>
          For the final build, leds were taken away and neopixel strips were used to get the desired led effects. Neopixel rings also gave robot proper smile and frown as compared to the prototype build. An eyebrow was also added above the eye of robot to give the robot human characteristics and make users sympathise with it. This addition goes along with anthropomorphism of robot. The arduino code was rewritten to work with the positive interactions and neopixel strips. Other teammate's individual aspect was also combined with my build, which enables the robot to talk when it is angry and when positive interaction is used.
        </p>
        <img src="img/final_build.jpg" class="design-images-two rounded mx-auto d-block">
        <p class="text-center"> *Finished Product* </p>
        <p>
          For the final deliverable, the build above was combined with each team memeber's individual aspects. Here we bought together the audio feedback and visual hacking together in one code. A demo of final product can be seen in the video below -
        </p>
        <div class="embed-responsive embed-responsive-21by9">
          <iframe class="embed-responsive-item" width="560" height="315" src="https://www.youtube.com/embed/xgeL5xilRyk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
      <hr>

      <div id="reflection">
        <h2>Reflection on project outcomes</h2>
        <hr class="h2-underline text-left"></hr>
        <p style="padding-left:4%; padding-right:4%;">
          Overall, I am contented with the project and what it delivers. Concept development, design process and bringing everything together was a wonderful experience. The ideal concept and actual project aren’t very far away. The ideal concept promises user some features that couldn’t be delivered in the final product. With the availability of time, I would have liked to include some more effects similar to smile and frown, like moving ears. Currently, the robot has the ability to process an interaction but due to lack of time and resources, it can't take action like turning off TV or stop Roomba. For example, the robot can input when it’s view is blocked but the robot can’t stop moving (something the concept promises) because the team couldn’t get the Roomba working properly with robot though it was tried by Tim.  These minute details are present in interaction’s concept but not in the final build.
          <br>
          The project in itself delivers well on it’s domain of Sassy Tech where the robot acts as sass machine. The robot being able to deliver sass through various mediums such as talk & device control and it’s ability to respond to sass based on user’s action fits perfectly within Sassy Tech. The underlying problem we are trying to resolve about people overusing screens is also tackled well by concept. A weak point of the concept is that it doesn’t have a proper background research present which explains the theory behind behaviour change and motivation. If the robot is there a person’s screen time may be reduced but there’s no guarantee that this change would be a long-term effect. This is something I wish we had explored more. In the overall studio theme of playful and open-ended interactions for everyday life, the robot can be easily seen as something user interacts daily and has fun interacting with it in various ways present. The interactions are playful in sense that they allow users to interact and responds to the user interaction through reactions and different mediums. I think we covered this area pretty well. The robot is intended to be for everyday usage but I personally think our concept here can improve. We haven't thought well about when the robot stays active and how long it stays active. Also, there is no mention about usage of product when user complies to it and stop watching the TV. These are some further considerations I would explore if given more time and resources. To conclude, the concept ticks all the required points but still some minor changes can be made.
        </p>
        <h5 style="padding-left: 4%;">Online Exhibit:</h5>
          <p style="padding-left:4%; padding-right:4%;">
            Online exhibit was a wonderful experience which bought some further insights into the concept and what it can become. Overall, the concept had positive feedback where viewers actively engaged with what the concept meant and what features it could include. It was great to see that visitors ask questions about the interactions and derive emotional connection to robot, which was one of the success criterias. We would have loved to measure other criterias as well where we would measure if the robot actually reduced screen time but those required prolonged usage which was not possible in an online exhibit. We also had some trouble with failing parts during the exhibit and individual aspects not coming like we expected so, we had to roll back to individual components working independently. We simulated the individual parts and made them look like one so viewer's experience doesn't get degrade. The cause of failing parts was that all individual parts were connected to one voltage that started smoking after working for a bit. We should have anticipated this and prepared for any last minute failures. Seeing the overall reactions, I would say the prototype worked and we took the right approach towards the problem space. Some feedback we got on the broader concept relates to how concept can further develop to become a personal assitant and it would botch up it's tasks as sass expression. It would be a great direction to explore more sassy ways to annoy users. Overall, the visitors were interested in the product and contented with it's interactions.
          </p>
      </div>
    </div>
    <hr style="margin-top: 3%;">
    <!-- Other Work -->
    <div class="container-fluid padding">
      <div class="row text-center padding">
        <div class="col-12">
          <h1 class="text-center text-info"><em><u>Outputs</u></em></h1>
        </div>
        <div class="col-12 padding">
          <button type="button" class="btn btn-color-select" data-toggle="tooltip" data-placement="top" title="Journals: Checkout Journals to explore more about design process and how it developed through the weeks">
            <a href="https://deco3850.uqcloud.net/students/amander" class="other-deliverables-links">Journals</a>
          </button>
          <button type="button" class="btn btn-color-select" data-toggle="tooltip" data-placement="top" title="Proposal Pitch: Look at our first pitch before we came up with concept of SassMobile">
            <a href="https://docs.google.com/presentation/d/1lpZErC9YnARJC8bCYhF2fxXDVdksjeFY-k74s62O1zw/edit?usp=sharing" class="other-deliverables-links">Proposal Pitch</a>
          </button>
          <button type="button" class="btn btn-color-select" data-toggle="tooltip" data-placement="top" title="Project Ideas & Inspirations: In our first assessment, we created a poster pitching idea for our studio theme">
            <a href="https://drive.google.com/file/d/1-JnPuKohmfEihpbMcfhKf74K9ecOy3xa/view?usp=sharing" class="other-deliverables-links">Project Ideas & Inspirations</a>
          </button>
        </div>
      </div>
    </div>
    <hr>

    <footer>
      <h2 class="contact-text"><u>Contact Info</u></h2>
      <p class="text-center">e-mail: mander.anshuman@gmail.com<br>Insta: manderanshuman</p>
      <p class="text-center">Website built with <a href="https://getbootstrap.com/">Bootstrap</a></p>
    </footer>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
  </body>
</html>
